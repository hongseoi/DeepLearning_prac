{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. 이변수 함수\n",
    "$$\n",
    "f(x,y)=xy\n",
    "$$\n",
    "에 대하여 learning rate $\\eta=1$로 AdaGrad를 적용하려 한다.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(i) 초기 위치 ${\\bf x}_0=(1,2)$에서 출발하여 두 발자국 걸어갈때, ${\\bf x}_1$, ${\\bf x}_2$를 구하시오.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "편미분하여 그레디언트\n",
    "$$\n",
    "\\nabla f (x,y) = (y,x)\n",
    "$$\n",
    "를 구합니다.  \n",
    "그레디언트의 좌표별 제곱을 구해서 학습율을 보정합니다.\n",
    "$$\n",
    "\\begin{aligned}\n",
    "{\\bf h_0} &= \\nabla f({\\bf x_0}) \\odot \\nabla f({\\bf x_0}) = (4,1) \\\\\n",
    "{\\bf x_1} &= {\\bf x_0} - \\eta {1 \\over \\sqrt{\\bf h_0}} \\odot \\nabla f({\\bf x_0}) = (1,2) - {1 \\over (2,1)} \\odot (2,1) = (0,1)\n",
    "\\end{aligned}\n",
    "$$\n",
    "두번째는 그레디언트의 좌표별 제곱을 구해서 기존의 값에 더합니다.\n",
    "$$\n",
    "\\begin{aligned}\n",
    "{\\bf h_1} &= {\\bf h_0} + \\nabla f({\\bf x_1}) \\odot \\nabla f({\\bf x_1}) = (4,1) + (1,0) = (5,1)\\\\\n",
    "{\\bf x_2} &= {\\bf x_1} - \\eta {1 \\over \\sqrt{\\bf h_1}} \\odot \\nabla f({\\bf x_1}) = (0,1) - {1 \\over (\\sqrt{5},1)} \\odot (1,0) = (-{1 \\over \\sqrt{5}}, 1)\n",
    "\\end{aligned}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(ii) 코드로 검산하시오**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'x': 4.99999973646581e-08, 'y': 1.00000009999999}\n",
      "{'x': -0.4472135612770433, 'y': 1.0000000499999977}\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('C://Users//HAN//Documents//Deep Learning from Scratch') # 각자의 경로로 수정해주세요.\n",
    "import numpy as np\n",
    "from common.optimizer import AdaGrad\n",
    "\n",
    "optimizer = AdaGrad(1)\n",
    "\n",
    "params = {'x':1.,'y':2.}\n",
    "\n",
    "def df():\n",
    "    return {'x': params['y'], 'y' : params['x']}\n",
    "\n",
    "for step in range(2):\n",
    "    grads = df()\n",
    "    optimizer.update(params,grads)\n",
    "    print(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4472135954999579\n"
     ]
    }
   ],
   "source": [
    "print(1/np.sqrt(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. 이변수 함수\n",
    "$$\n",
    "f(x,y)=x^2 + xy\n",
    "$$\n",
    "에 대하여 learning rate $\\eta={1 \\over 2}$로 AdaGrad를 적용하려 한다.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(i) 초기 위치 ${\\bf x}_0=(1,1)$에서 출발하여 두 발자국 걸어갈때, ${\\bf x}_1$, ${\\bf x}_2$를 구하시오.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "편미분하여 그레디언트\n",
    "$$\n",
    "\\nabla f (x,y) = (2x+y,x)\n",
    "$$\n",
    "를 구합니다.  \n",
    "그레디언트의 좌표별 제곱을 구해서 학습율을 보정합니다.\n",
    "$$\n",
    "\\begin{aligned}\n",
    "{\\bf h_0} &= \\nabla f({\\bf x_0}) \\odot \\nabla f({\\bf x_0}) = (9,1) \\\\\n",
    "{\\bf x_1} &= {\\bf x_0} - \\eta {1 \\over \\sqrt{\\bf h_0}} \\odot \\nabla f({\\bf x_0}) = (1,1) - {1 \\over 2(3,1)} \\odot (3,1) = ({1 \\over 2},{1 \\over 2})\n",
    "\\end{aligned}\n",
    "$$\n",
    "두번째는 그레디언트의 좌표별 제곱을 구해서 기존의 값에 더합니다.\n",
    "$$\n",
    "\\begin{aligned}\n",
    "{\\bf h_1} &= {\\bf h_0} + \\nabla f({\\bf x_1}) \\odot \\nabla f({\\bf x_1}) = (9,1) + ({9 \\over 4},{1 \\over 4}) = ({45 \\over 4},{5 \\over 4})\\\\\n",
    "{\\bf x_2} &= {\\bf x_1} - \\eta {1 \\over \\sqrt{\\bf h_1}} \\odot \\nabla f({\\bf x_1}) = ({1 \\over 2},{1 \\over 2}) - {1 \\over 2(\\sqrt{45/4},\\sqrt{5/4})} \\odot ({3 \\over 2},{1 \\over 2}) = ({1 \\over 2}-{1 \\over 2\\sqrt{5}}, {1 \\over 2}-{1 \\over 2\\sqrt{5}})\n",
    "\\end{aligned}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(ii) 코드로 검산하시오**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'x': 0.500000016666666, 'y': 0.500000049999995}\n",
      "{'x': 0.27639321564527475, 'y': 0.27639326628716704}\n"
     ]
    }
   ],
   "source": [
    "optimizer = AdaGrad(1/2)\n",
    "\n",
    "params = {'x':1.,'y':1.}\n",
    "\n",
    "def df():\n",
    "    return {'x': 2*params['x']+params['y'], 'y' : params['x']}\n",
    "\n",
    "for step in range(2):\n",
    "    grads = df()\n",
    "    optimizer.update(params,grads)\n",
    "    print(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.27639320225002106"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1/2 - 1/(2*np.sqrt(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3. 이변수 함수\n",
    "$$\n",
    "f(x,y)=xy\n",
    "$$\n",
    "에 대하여 learning rate $\\eta=1$과 forgetting factor $\\gamma=3/4$으로 RMSProp을 적용하려 한다.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(i) 초기 위치 ${\\bf x}_0=(1,2)$에서 출발하여 두 발자국 걸어갈때, ${\\bf x}_1$, ${\\bf x}_2$를 구하시오.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "편미분하여 그레디언트\n",
    "$$\n",
    "\\nabla f (x,y) = (y,x)\n",
    "$$\n",
    "를 구합니다.  \n",
    "그레디언트의 좌표별 제곱을 구해서 학습율을 보정합니다.  \n",
    "RMSProp이 AdaGrad와 다른 점은 기존의 값과 가중치 평균을 한다는 것입니다.  \n",
    "출발점에서는 기존의 값을 $(0,0)$으로 생각합니다.\n",
    "$$\n",
    "\\begin{aligned}\n",
    "{\\bf h_0} &= \\gamma (0,0) + (1-\\gamma) \\nabla f({\\bf x_0}) \\odot \\nabla f({\\bf x_0}) = {3 \\over 4}(0,0) + {1 \\over 4}(4,1) = (1, {1 \\over 4})\\\\\n",
    "{\\bf x_1} &= {\\bf x_0} - \\eta {1 \\over \\sqrt{\\bf h_0}} \\odot \\nabla f({\\bf x_0}) = (1,2) - {1 \\over (1,1/2)} \\odot (2,1) = (-1,0)\n",
    "\\end{aligned}\n",
    "$$\n",
    "두번째는 그레디언트의 좌표별 제곱을 구해서 첫번째에서 구한 값과 가중치 평균을 합니다.\n",
    "$$\n",
    "\\begin{aligned}\n",
    "{\\bf h_1} &= \\gamma {\\bf h_0} + (1-\\gamma) \\nabla f({\\bf x_1}) \\odot \\nabla f({\\bf x_1}) = {3 \\over 4}(1,{1 \\over 4}) + {1 \\over 4}(0,1) = ({3 \\over 4},{7 \\over 16})\\\\\n",
    "{\\bf x_2} &= {\\bf x_1} - \\eta {1 \\over \\sqrt{\\bf h_1}} \\odot \\nabla f({\\bf x_1}) = (-1,0) - {1 \\over (\\sqrt{3}/2,\\sqrt{7}/4)} \\odot (0,-1) = (-1, {4 \\over \\sqrt{7}})\n",
    "\\end{aligned}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(ii) 코드로 검산하시오**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'x': -0.9999998000000199, 'y': 3.999999198533999e-07}\n",
      "{'x': -1.0000002618800894, 'y': 1.5118579338775995}\n"
     ]
    }
   ],
   "source": [
    "from common.optimizer import RMSprop\n",
    "\n",
    "optimizer = RMSprop(1,3/4)\n",
    "\n",
    "params = {'x':1.,'y':2.}\n",
    "\n",
    "def df():\n",
    "    return {'x': params['y'], 'y' : params['x']}\n",
    "\n",
    "for step in range(2):\n",
    "    grads = df()\n",
    "    optimizer.update(params,grads)\n",
    "    print(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.5118578920369088"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "4/np.sqrt(7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4. 이변수 함수\n",
    "$$\n",
    "f(x,y)=x^2 + xy\n",
    "$$\n",
    "에 대하여 learning rate $\\eta={1 \\over 2}$과 forgetting factor $\\gamma=8/9$으로 RMSProp을 적용하려 한다.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(i) 초기 위치 ${\\bf x}_0=(1,1)$에서 출발하여 두 발자국 걸어갈때, ${\\bf x}_1$, ${\\bf x}_2$를 구하시오.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "편미분하여 그레디언트\n",
    "$$\n",
    "\\nabla f (x,y) = (2x+y,x)\n",
    "$$\n",
    "를 구합니다.  \n",
    "그레디언트의 좌표별 제곱을 구해서 학습율을 보정합니다.  \n",
    "RMSProp이 AdaGrad와 다른 점은 기존의 값과 가중치 평균을 한다는 것입니다.  \n",
    "출발점에서는 기존의 값을 $(0,0)$으로 생각합니다.\n",
    "$$\n",
    "\\begin{aligned}\n",
    "{\\bf h_0} &= \\gamma (0,0) + (1-\\gamma) \\nabla f({\\bf x_0}) \\odot \\nabla f({\\bf x_0}) = {8 \\over 9}(0,0) + {1 \\over 9}(9,1) = (1, {1 \\over 9})\\\\\n",
    "{\\bf x_1} &= {\\bf x_0} - \\eta {1 \\over \\sqrt{\\bf h_0}} \\odot \\nabla f({\\bf x_0}) = (1,1) - {1 \\over 2(1,1/3)} \\odot (3,1) = (-{1 \\over 2},-{1 \\over 2})\n",
    "\\end{aligned}\n",
    "$$\n",
    "두번째는 그레디언트의 좌표별 제곱을 구해서 첫번째에서 구한 값과 가중치 평균을 합니다.\n",
    "$$\n",
    "\\begin{aligned}\n",
    "{\\bf h_1} &= \\gamma {\\bf h_0} + (1-\\gamma) \\nabla f({\\bf x_1}) \\odot \\nabla f({\\bf x_1}) = {8 \\over 9}(1,{1 \\over 9}) + {1 \\over 9}({9 \\over 4},{1 \\over 4}) = ({41 \\over 36},{41 \\over 9^2\\times4})\\\\\n",
    "{\\bf x_2} &= {\\bf x_1} - \\eta {1 \\over \\sqrt{\\bf h_1}} \\odot \\nabla f({\\bf x_1}) = (-{1 \\over 2},-{1 \\over 2}) - {1 \\over 2(\\sqrt{41}/6,\\sqrt{41}/(9\\times2))} \\odot (-{3 \\over 2},-{1 \\over 2}) = (-{1 \\over 2} +{9 \\over 2\\sqrt{41}}, -{1 \\over 2} +{9 \\over 2\\sqrt{41}})\n",
    "\\end{aligned}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(ii) 코드로 검산하시오**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'x': -0.4999998500000147, 'y': -0.49999955000013463}\n",
      "{'x': 0.20278173838873104, 'y': 0.20278201638388815}\n"
     ]
    }
   ],
   "source": [
    "optimizer = RMSprop(1/2,8/9)\n",
    "\n",
    "params = {'x':1.,'y':1.}\n",
    "\n",
    "def df():\n",
    "    return {'x': 2*params['x']+params['y'], 'y' : params['x']}\n",
    "\n",
    "for step in range(2):\n",
    "    grads = df()\n",
    "    optimizer.update(params,grads)\n",
    "    print(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.20278192849872734"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "-1/2 + 9/(2*np.sqrt(41))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
