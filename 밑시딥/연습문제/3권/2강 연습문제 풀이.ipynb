{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. 다음 말뭉치(corpus)에 대해서  윈도우 크기를 1과 2로 잡았을 때 교재 코드를 사용하여 PPMI행렬을 각각 출력하시오.**\n",
    "\n",
    "**The sky is very blue and the sky is very beautiful today.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.    2.    0.    0.    0.    2.    0.    0.    0.   ]\n",
      " [2.    0.    1.585 0.    0.    0.    0.    0.    0.   ]\n",
      " [0.    1.585 0.    1.585 0.    0.    0.    0.    0.   ]\n",
      " [0.    0.    1.585 0.    1.585 0.    1.585 0.    0.   ]\n",
      " [0.    0.    0.    1.585 0.    2.585 0.    0.    0.   ]\n",
      " [2.    0.    0.    0.    2.585 0.    0.    0.    0.   ]\n",
      " [0.    0.    0.    1.585 0.    0.    0.    2.585 0.   ]\n",
      " [0.    0.    0.    0.    0.    0.    2.585 0.    3.585]\n",
      " [0.    0.    0.    0.    0.    0.    0.    3.585 0.   ]]\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('C://Users//HAN//Documents//Deep Learning from Scratch 2') # 각자의 경로로 수정해주세요.\n",
    "import numpy as np\n",
    "from common.util import preprocess, create_co_matrix, cos_similarity, ppmi\n",
    "\n",
    "text = 'The sky is very blue and the sky is very beautiful today.'\n",
    "corpus, word_to_id, id_to_word = preprocess(text)\n",
    "vocab_size = len(word_to_id)\n",
    "C1 = create_co_matrix(corpus, vocab_size)\n",
    "W1 = ppmi(C1)\n",
    "np.set_printoptions(precision=3)\n",
    "print(W1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.    1.131 0.939 0.    0.939 0.939 0.    0.    0.   ]\n",
      " [1.131 0.    0.716 0.716 0.    0.716 0.    0.    0.   ]\n",
      " [0.939 0.716 0.    0.524 0.524 0.    0.524 0.    0.   ]\n",
      " [0.    0.716 0.524 0.    0.524 0.524 0.524 0.939 0.   ]\n",
      " [0.939 0.    0.524 0.524 0.    1.524 0.    0.    0.   ]\n",
      " [0.939 0.716 0.    0.524 1.524 0.    0.    0.    0.   ]\n",
      " [0.    0.    0.524 0.524 0.    0.    0.    1.939 2.524]\n",
      " [0.    0.    0.    0.939 0.    0.    1.939 0.    2.939]\n",
      " [0.    0.    0.    0.    0.    0.    2.524 2.939 0.   ]]\n"
     ]
    }
   ],
   "source": [
    "C2 = create_co_matrix(corpus, vocab_size, 2)\n",
    "W2 = ppmi(C2)\n",
    "print(W2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2.확률 변수 $X$, $Y$의 확률분포가 다음과 같이 주어져 있다.\n",
    "$$\n",
    "\\begin{matrix}\n",
    "Y \\backslash X&1&2&3&4 \\\\\\hline\n",
    "1 &1/8&1/16&1/32&1/32 \\\\\n",
    "2 &1/16&1/8&1/32&1/32 \\\\\n",
    "3 &1/16&1/16&1/16&1/16 \\\\\n",
    "4 &1/4&0&0&0\\\\\\hline\n",
    "\\end{matrix}\n",
    "$$**\n",
    "\n",
    "**(i) PMI 테이블과 PPMI 테이블을 구하시오.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "동시발생행렬로부터 PMI 행렬을 만들때는 먼저 전체 합으로 나눠서 확률분포로 변형합니다.  \n",
    "이 문제는 주어진 테이블이 이미 확률분포이므로 전체 합으로 나눌 필요가 없습니다.  \n",
    "행과 열을 합해서 marginal distribution을 먼저 구하죠.\n",
    "$$\n",
    "\\begin{matrix}\n",
    "&Y&X \\\\\\hline\n",
    "1 &1/4&1/2 \\\\\n",
    "2 &1/4&1/4 \\\\\n",
    "3 &1/4&1/8 \\\\\n",
    "4 &1/4&1/8 \\\\\\hline\n",
    "\\end{matrix}\n",
    "$$\n",
    "pointwise mutual information $\\log_2 {p(y,x) \\over p(y)p(x)}$를 적용하면\n",
    "$$\n",
    "\\begin{matrix}\n",
    "Y \\backslash X&1&2&3&4 \\\\\\hline\n",
    "1 &\\log_2 {1/8 \\over 1/4 \\times 1/2}&\\log_2 {1/16 \\over 1/4 \\times 1/4}&\\log_2 {1/32 \\over 1/4 \\times 1/8}&\\log_2 {1/32 \\over 1/4 \\times 1/8} \\\\\n",
    "2 &\\log_2 {1/16 \\over 1/4 \\times 1/2}&\\log_2 {1/8 \\over 1/4 \\times 1/4}&\\log_2 {1/32 \\over 1/4 \\times 1/8}&\\log_2 {1/32 \\over 1/4 \\times 1/8} \\\\\n",
    "3 &\\log_2 {1/16 \\over 1/4 \\times 1/2}&\\log_2 {1/16 \\over 1/4 \\times 1/4}&\\log_2 {1/16 \\over 1/4 \\times 1/8}&\\log_2 {1/16 \\over 1/4 \\times 1/8} \\\\\n",
    "4 &\\log_2 {1/4 \\over 1/4 \\times 1/2}&\\log_2 {0 \\over 1/4 \\times 1/4}&\\log_2 {0 \\over 1/4 \\times 1/8}&\\log_2 {0 \\over 1/4 \\times 1/8}\\\\\\hline\n",
    "\\end{matrix}\n",
    "$$\n",
    "이고 정리하면 다음과 같은 PMI 행렬을 얻습니다.\n",
    "$$\n",
    "\\begin{matrix}\n",
    "Y \\backslash X&1&2&3&4 \\\\\\hline\n",
    "1 &0&0&0&0 \\\\\n",
    "2 &-1&1&0&0 \\\\\n",
    "3 &-1&0&1&1 \\\\\n",
    "4 &1&-\\infty&-\\infty&-\\infty\\\\\\hline\n",
    "\\end{matrix}\n",
    "$$\n",
    "여기에서 음수를 0으로 모두 바꿔버리면 PPMI 행렬을 쉽게 얻습니다.\n",
    "$$\n",
    "\\begin{matrix}\n",
    "Y \\backslash X&1&2&3&4 \\\\\\hline\n",
    "1 &0&0&0&0 \\\\\n",
    "2 &0&1&0&0 \\\\\n",
    "3 &0&0&1&1 \\\\\n",
    "4 &1&0&0&0\\\\\\hline\n",
    "\\end{matrix}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(ii) 교재의 PPMI 코드는 대칭행렬을 가정하고 작성된 코드이다. 일반적인 행렬에도 적용되도록 코드를 수정한뒤 (i)의 결과를 검산하시오.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "교재의 PPMI 코드를 그대로 적용하면 손으로 계산한 결과와 맞아 떨어지지 않습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.000e+00 0.000e+00 0.000e+00 0.000e+00]\n",
      " [0.000e+00 1.000e+00 1.443e-08 1.443e-08]\n",
      " [1.443e-08 1.000e+00 2.000e+00 2.000e+00]\n",
      " [2.000e+00 0.000e+00 0.000e+00 0.000e+00]]\n"
     ]
    }
   ],
   "source": [
    "table = np.array([[1/8,1/16,1/32,1/32],[1/16,1/8,1/32,1/32],[1/16,1/16,1/16,1/16],[1/4,0,0,0]])\n",
    "W = ppmi(table)\n",
    "print(W)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "다음은 교재의 PPMI 코드인데 S는 열들의 합이어서 이 문제에서는 $X$의 확률분포가 됩니다.  \n",
    "동시발생행렬은 항상 대칭행렬이므로 `np.log2(C[i, j] * N / (S[j]*S[i])`는 별 문제없이 작동합니다.  \n",
    "이 예제는 대칭행렬이 아니므로 그대로 적용하면 안됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ppmi(C, verbose=False, eps = 1e-8):    \n",
    "    M = np.zeros_like(C, dtype=np.float32)\n",
    "    N = np.sum(C)\n",
    "    S = np.sum(C, axis=0)\n",
    "    total = C.shape[0] * C.shape[1]\n",
    "    cnt = 0\n",
    "\n",
    "    for i in range(C.shape[0]):\n",
    "        for j in range(C.shape[1]):\n",
    "            pmi = np.log2(C[i, j] * N / (S[j]*S[i]) + eps)\n",
    "            M[i, j] = max(0, pmi)\n",
    "\n",
    "            if verbose:\n",
    "                cnt += 1\n",
    "                if cnt % (total//100) == 0:\n",
    "                    print('%.1f%% 완료' % (100*cnt/total))\n",
    "    return M"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "행의 합을 따로 정의하고 pmi 값에 이를 반영하도록 ppmi 코드를 수정합니다.  \n",
    "그러면 위 손 계산과 일치한 결과가 나옵니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.443e-08 1.443e-08 1.443e-08 1.443e-08]\n",
      " [0.000e+00 1.000e+00 1.443e-08 1.443e-08]\n",
      " [0.000e+00 1.443e-08 1.000e+00 1.000e+00]\n",
      " [1.000e+00 0.000e+00 0.000e+00 0.000e+00]]\n"
     ]
    }
   ],
   "source": [
    "def ppmi(C, verbose=False, eps = 1e-8):    \n",
    "    M = np.zeros_like(C, dtype=np.float32)\n",
    "    N = np.sum(C)\n",
    "    S_col = np.sum(C, axis=0)\n",
    "    S_row = np.sum(C, axis=1)\n",
    "    total = C.shape[0] * C.shape[1]\n",
    "    cnt = 0\n",
    "\n",
    "    for i in range(C.shape[0]):\n",
    "        for j in range(C.shape[1]):\n",
    "            pmi = np.log2(C[i, j] * N / (S_col[j]*S_row[i]) + eps)\n",
    "            M[i, j] = max(0, pmi)\n",
    "\n",
    "            if verbose:\n",
    "                cnt += 1\n",
    "                if cnt % (total//100) == 0:\n",
    "                    print('%.1f%% 완료' % (100*cnt/total))\n",
    "    return M\n",
    "\n",
    "W = ppmi(table)\n",
    "print(W)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3. `count_method_big.py`를 기반으로 다음 코드를 작성하시오.**\n",
    "\n",
    "**(i) 동시발생행렬과 PPMI행렬 계산결과를 pickle파일에 저장하시오.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "동시발생 수 계산 ...\n",
      "PPMI 계산 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HAN\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:11: RuntimeWarning: overflow encountered in long_scalars\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "C:\\Users\\HAN\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:11: RuntimeWarning: invalid value encountered in log2\n",
      "  # This is added back by InteractiveShellApp.init_path()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved!\n"
     ]
    }
   ],
   "source": [
    "from dataset import ptb\n",
    "import pickle\n",
    "\n",
    "window_size = 2\n",
    "\n",
    "corpus, word_to_id, id_to_word = ptb.load_data('train')\n",
    "vocab_size = len(word_to_id)\n",
    "print('동시발생 수 계산 ...')\n",
    "C = create_co_matrix(corpus, vocab_size, window_size)\n",
    "print('PPMI 계산 ...')\n",
    "W = ppmi(C)\n",
    "data=[C,W]\n",
    "with open('data.pkl', 'wb') as f:\n",
    "    pickle.dump(data,f)\n",
    "print(\"Saved!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(ii) (i)의 pickle파일을 불러온 후 PPMI행렬 대신 동시발생행렬에 대하여 SVD를 적용한 후 you, year, car, toyota와 코사인 유사도가 가장 높은 5개의 단어를 출력하시오. 기존 결과와 비교하고 이유를 해석하시오.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "교재에서는 동시발생행렬 → PPMI 행렬 → 차원축소의 과정을 거쳐 벡터표현을 얻었습니다.  \n",
    "동시발생행렬은 주변 단어의 개수를 세어서 얻어진 단어들의 벡터 표현입니다.  \n",
    "사람을 알기 위해 그 친구를 보는 셈이지요.  \n",
    "하지만, a나 the와 같이 너무 자주 등장하는 단어는 등장빈도에 비해 정보를 많이 주지는 않습니다.  \n",
    "반대로 비사교적인 사람의 친구는 취미라던지 어딘가 통하는 게 있겠지요.  \n",
    "PPMI는 등장빈도가 적을 수록 더 가중치를 부여합니다.  \n",
    "이를 통해 단어의 벡터표현이 단어의 의미를 더 많이 담아 내도록 합니다.  \n",
    "PPMI 행렬이 실제로 이런 역할을 하는지 실험을 해보죠.  \n",
    "PPMI 행렬을 건너 띄고 얻는 벡터표현들에 대해 코사인 유사도 값이 높은 단어들을 확인해보세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded!\n",
      "\n",
      "[query] you\n",
      " we: 0.8493554716566818\n",
      " survive: 0.6988542518880129\n",
      " wondering: 0.5238895279001866\n",
      " texans: 0.519372252599928\n",
      " relieve: 0.4955882883808545\n",
      "\n",
      "[query] year\n",
      " month: 0.4056048076441138\n",
      " discovision: 0.30618598877951\n",
      " celebrity: 0.29021387850472974\n",
      " microsoft: 0.28416022569030946\n",
      " trinity: 0.2732095314089362\n",
      "\n",
      "[query] car\n",
      " wendy: 0.6341232945621402\n",
      " kong: 0.634106902719846\n",
      " manufacturing: 0.5985899161026185\n",
      " filling: 0.5924201150513638\n",
      " near-term: 0.5911872493069659\n",
      "\n",
      "[query] toyota\n",
      " mcdonnell: 0.7872455538682231\n",
      " motors: 0.7710814798546892\n",
      " digital: 0.756499086341536\n",
      " mazda: 0.7545255301568434\n",
      " brown-forman: 0.74650081028442\n"
     ]
    }
   ],
   "source": [
    "from common.util import most_similar\n",
    "\n",
    "with open('data.pkl', 'rb') as f:\n",
    "    data=pickle.load(f)\n",
    "print(\"Loaded!\")\n",
    "C=data[0]\n",
    "wordvec_size=100\n",
    "\n",
    "from sklearn.utils.extmath import randomized_svd\n",
    "U, S, V = randomized_svd(C, n_components=wordvec_size, n_iter=5,random_state=None)\n",
    "\n",
    "word_vecs = U[:, :wordvec_size]\n",
    "\n",
    "querys = ['you', 'year', 'car', 'toyota']\n",
    "for query in querys:\n",
    "    most_similar(query, word_to_id, id_to_word, word_vecs, top=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(iii) (i)의 pickle파일을 불러온 후 벡터표현의 차원을 각각 5, 20, 100으로 잡았을 때 you, year, car, toyota와 코사인 유사도가 가장 높은 5개의 단어를 각각 출력하시오. 기존 결과와 비교하고 이유를 해석하시오.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PTB 데이터셋에 등장하는 어휘는 10,000개이기 때문에 PPMI 행렬을 통해 얻은 단어의 벡터 표현은 무려 10,000차원입니다.  \n",
    "신경망의 입력 뉴런의 개수도 10,000개여야 하는데 학습시간도 오래걸리고 과적합에 빠지기도 쉽습니다.  \n",
    "교재에서는 SVD를 통해 가급적 정보의 손실은 최소화하면서 벡터의 차원을 100으로 줄입니다.  \n",
    "벡터의 차원을 줄이면 줄일수록 좋을까요?  \n",
    "벡터의 차원은 정보를 담을 그릇의 크기와 같습니다.  \n",
    "차원을 너무 줄이면 중요한 정보조차도 담을 수 없습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded!\n",
      "wordvec_size=5\n",
      "\n",
      "[query] you\n",
      " do: 0.9865080118179321\n",
      " we: 0.9854855537414551\n",
      " 'm: 0.9788055419921875\n",
      " how: 0.9775410294532776\n",
      " 're: 0.9767671823501587\n",
      "\n",
      "[query] year\n",
      " last: 0.9893128871917725\n",
      " month: 0.98704993724823\n",
      " week: 0.9740935564041138\n",
      " yesterday: 0.9726187586784363\n",
      " since: 0.9693969488143921\n",
      "\n",
      "[query] car\n",
      " financing: 0.9918797016143799\n",
      " global: 0.991134762763977\n",
      " internal: 0.9902976751327515\n",
      " nation: 0.9878718852996826\n",
      " product: 0.9848695397377014\n",
      "\n",
      "[query] toyota\n",
      " dutch: 0.9973098039627075\n",
      " nabisco: 0.9933227300643921\n",
      " publishes: 0.9928234815597534\n",
      " england: 0.9923238754272461\n",
      " mining: 0.9916982650756836\n",
      "==================================================\n",
      "wordvec_size=20\n",
      "\n",
      "[query] you\n",
      " 'll: 0.9102431535720825\n",
      " me: 0.9079532027244568\n",
      " i: 0.9015957117080688\n",
      " we: 0.8940824270248413\n",
      " us: 0.8902565240859985\n",
      "\n",
      "[query] year\n",
      " earlier: 0.8362162113189697\n",
      " period: 0.8306176066398621\n",
      " months: 0.8146306276321411\n",
      " month: 0.8118310570716858\n",
      " last: 0.7880735397338867\n",
      "\n",
      "[query] car\n",
      " auto: 0.8481684923171997\n",
      " luxury: 0.8027188777923584\n",
      " machine: 0.7865602970123291\n",
      " truck: 0.7676756381988525\n",
      " production: 0.7631547451019287\n",
      "\n",
      "[query] toyota\n",
      " chevrolet: 0.9010553359985352\n",
      " motor: 0.8882524967193604\n",
      " hoechst: 0.8752568960189819\n",
      " brown-forman: 0.8449079394340515\n",
      " tandem: 0.8431305289268494\n",
      "==================================================\n",
      "wordvec_size=100\n",
      "\n",
      "[query] you\n",
      " we: 0.6482522487640381\n",
      " i: 0.6306846141815186\n",
      " do: 0.5741670727729797\n",
      " always: 0.5331050753593445\n",
      " anybody: 0.529975175857544\n",
      "\n",
      "[query] year\n",
      " month: 0.67417311668396\n",
      " earlier: 0.6110426187515259\n",
      " last: 0.5940330624580383\n",
      " quarter: 0.5911180973052979\n",
      " next: 0.5898612141609192\n",
      "\n",
      "[query] car\n",
      " auto: 0.6890864372253418\n",
      " luxury: 0.6761255860328674\n",
      " cars: 0.5961717367172241\n",
      " vehicle: 0.5212932825088501\n",
      " lexus: 0.5081124305725098\n",
      "\n",
      "[query] toyota\n",
      " motors: 0.6886743307113647\n",
      " motor: 0.6848162412643433\n",
      " honda: 0.5974385738372803\n",
      " mazda: 0.5931745171546936\n",
      " lexus: 0.5915335416793823\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "with open('data.pkl', 'rb') as f:\n",
    "    data=pickle.load(f)\n",
    "print(\"Loaded!\")\n",
    "W=data[1]\n",
    "wordvec_size=[5,20,100]\n",
    "\n",
    "from sklearn.utils.extmath import randomized_svd\n",
    "U, S, V = randomized_svd(W, n_components=100, n_iter=5,random_state=None)\n",
    "\n",
    "querys = ['you', 'year', 'car', 'toyota']\n",
    "\n",
    "for i in wordvec_size:\n",
    "    word_vecs = U[:, :i]\n",
    "    print('wordvec_size='+str(i))\n",
    "    for query in querys:\n",
    "        most_similar(query, word_to_id, id_to_word, word_vecs, top=5)\n",
    "    print('='*50)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
