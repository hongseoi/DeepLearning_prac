{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 데이터 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "data_dir = 'data'\n",
    "\n",
    "df = pd.read_csv(os.path.join(data_dir, 'ChatbotData.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Q</th>\n",
       "      <th>A</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12시 땡!</td>\n",
       "      <td>하루가 또 가네요.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1지망 학교 떨어졌어</td>\n",
       "      <td>위로해 드립니다.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3박4일 놀러가고 싶다</td>\n",
       "      <td>여행은 언제나 좋죠.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3박4일 정도 놀러가고 싶다</td>\n",
       "      <td>여행은 언제나 좋죠.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PPL 심하네</td>\n",
       "      <td>눈살이 찌푸려지죠.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Q            A  label\n",
       "0           12시 땡!   하루가 또 가네요.      0\n",
       "1      1지망 학교 떨어졌어    위로해 드립니다.      0\n",
       "2     3박4일 놀러가고 싶다  여행은 언제나 좋죠.      0\n",
       "3  3박4일 정도 놀러가고 싶다  여행은 언제나 좋죠.      0\n",
       "4          PPL 심하네   눈살이 찌푸려지죠.      0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 일상다반사\n",
    "df[df['label']==0].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Q</th>\n",
       "      <th>A</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5290</th>\n",
       "      <td>1000일 만난 여자친구와 이별</td>\n",
       "      <td>더 오래 만날 사람 만날 거예요.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5291</th>\n",
       "      <td>10년 연애. 헤어졌습니다.</td>\n",
       "      <td>더 공허함이 크시겠네요.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5292</th>\n",
       "      <td>10년 연애사 되돌아보니 다 부질없네</td>\n",
       "      <td>더 좋은 사람 만나실 거예요.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5293</th>\n",
       "      <td>10년 연예의끝</td>\n",
       "      <td>더 마음이 허하겠어요.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5294</th>\n",
       "      <td>10년만나다 헤어지네</td>\n",
       "      <td>충분히 슬퍼하고 충분히 아파하다가 이겨내세요.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         Q                          A  label\n",
       "5290     1000일 만난 여자친구와 이별         더 오래 만날 사람 만날 거예요.      1\n",
       "5291       10년 연애. 헤어졌습니다.              더 공허함이 크시겠네요.      1\n",
       "5292  10년 연애사 되돌아보니 다 부질없네           더 좋은 사람 만나실 거예요.      1\n",
       "5293              10년 연예의끝               더 마음이 허하겠어요.      1\n",
       "5294           10년만나다 헤어지네  충분히 슬퍼하고 충분히 아파하다가 이겨내세요.      1"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 이별\n",
    "df[df['label']==1].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Q</th>\n",
       "      <th>A</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8860</th>\n",
       "      <td>짝사랑만큼 고통스러운 건 없겠지.</td>\n",
       "      <td>짝사랑 만큼 감정소모가 큰 건 없을 거예요.</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8861</th>\n",
       "      <td>1년 넘게 만났는데 지금도 불타올라</td>\n",
       "      <td>정열적인 사랑을 하고 있나봐요.</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8862</th>\n",
       "      <td>1년 동거 중인데 계속 좋아</td>\n",
       "      <td>서로 깊게 알게되면서 더 좋아졌나봅니다.</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8863</th>\n",
       "      <td>1년 동거하고 결혼했어</td>\n",
       "      <td>축하합니다!</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8864</th>\n",
       "      <td>1년 만났는데도 그 사람에 대해 잘 모르겠어</td>\n",
       "      <td>더 만나보세요.</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             Q                         A  label\n",
       "8860        짝사랑만큼 고통스러운 건 없겠지.  짝사랑 만큼 감정소모가 큰 건 없을 거예요.      2\n",
       "8861       1년 넘게 만났는데 지금도 불타올라         정열적인 사랑을 하고 있나봐요.      2\n",
       "8862           1년 동거 중인데 계속 좋아    서로 깊게 알게되면서 더 좋아졌나봅니다.      2\n",
       "8863              1년 동거하고 결혼했어                    축하합니다!      2\n",
       "8864  1년 만났는데도 그 사람에 대해 잘 모르겠어                  더 만나보세요.      2"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 사랑\n",
    "df[df['label']==2].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = df['Q']\n",
    "answer = df['A']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "re.compile(r'[^ ?,.!A-Za-z0-9가-힣+]', re.UNICODE)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 데이터 전처리\n",
    "import re\n",
    "\n",
    "# 한글, 영어, 숫자, 공백, ?!.,을 제외한 나머지 문자 제거하는 정규 표현식 패턴 정의\n",
    "korean_pattern = r'[^ ?,.!A-Za-z0-9가-힣+]'\n",
    "\n",
    "# 패턴 컴파일\n",
    "normalizer = re.compile(korean_pattern)\n",
    "normalizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(sentence):\n",
    "    return normalizer.sub(\"\", sentence) # sentence 속에서 패턴과 일치하는 부분을 \"\"로 변경\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting konlpy\n",
      "  Downloading konlpy-0.6.0-py2.py3-none-any.whl.metadata (1.9 kB)\n",
      "Collecting JPype1>=0.7.0 (from konlpy)\n",
      "  Downloading JPype1-1.5.0-cp310-cp310-win_amd64.whl.metadata (5.0 kB)\n",
      "Collecting lxml>=4.1.0 (from konlpy)\n",
      "  Downloading lxml-5.2.2-cp310-cp310-win_amd64.whl.metadata (3.5 kB)\n",
      "Requirement already satisfied: numpy>=1.6 in c:\\users\\user\\anaconda3\\envs\\pytorch_tutorial\\lib\\site-packages (from konlpy) (1.26.4)\n",
      "Requirement already satisfied: packaging in c:\\users\\user\\anaconda3\\envs\\pytorch_tutorial\\lib\\site-packages (from JPype1>=0.7.0->konlpy) (24.0)\n",
      "Using cached konlpy-0.6.0-py2.py3-none-any.whl (19.4 MB)\n",
      "Downloading JPype1-1.5.0-cp310-cp310-win_amd64.whl (351 kB)\n",
      "   ---------------------------------------- 0.0/351.5 kB ? eta -:--:--\n",
      "   ------------------- -------------------- 174.1/351.5 kB 3.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 351.5/351.5 kB 5.5 MB/s eta 0:00:00\n",
      "Downloading lxml-5.2.2-cp310-cp310-win_amd64.whl (3.8 MB)\n",
      "   ---------------------------------------- 0.0/3.8 MB ? eta -:--:--\n",
      "   ---- ----------------------------------- 0.5/3.8 MB 14.5 MB/s eta 0:00:01\n",
      "   ---------- ----------------------------- 1.0/3.8 MB 13.1 MB/s eta 0:00:01\n",
      "   ---------------- ----------------------- 1.6/3.8 MB 12.7 MB/s eta 0:00:01\n",
      "   ---------------------- ----------------- 2.2/3.8 MB 12.5 MB/s eta 0:00:01\n",
      "   ------------------------ --------------- 2.3/3.8 MB 9.9 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 2.8/3.8 MB 9.8 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 3.2/3.8 MB 10.2 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 3.6/3.8 MB 9.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------  3.8/3.8 MB 8.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 3.8/3.8 MB 8.7 MB/s eta 0:00:00\n",
      "Installing collected packages: lxml, JPype1, konlpy\n",
      "Successfully installed JPype1-1.5.0 konlpy-0.6.0 lxml-5.2.2\n"
     ]
    }
   ],
   "source": [
    "! pip install konlpy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 한글 형태소 분석\n",
    "from konlpy.tag import Mecab, Okt\n",
    "okt = Okt()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 한글 전처리를 함수화\n",
    "def clean_text(sentence, tagger):\n",
    "    sentence = normalize(sentence) # 특수문자등 제거\n",
    "    sentence = tagger.morphs(sentence) # 형태소 분석\n",
    "    sentence = ' '.join(sentence) # 형태소로 나눠진 sentence list를 ' '으로 연결\n",
    "    sentence = sentence.lower() # 영어 등 lower\n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11823"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train data 전처리 및 형태소 분석 수행\n",
    "questions = [clean_text(sent, okt) for sent in question.values[:1000]]\n",
    "answers = [clean_text(sent, okt) for sent in answer.values[:1000]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['12시 땡 !', '1 지망 학교 떨어졌어', '3 박 4일 놀러 가고 싶다']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "questions[0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data.dataset import Dataset\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 단어 사전 WordVocab 생성\n",
    "\n",
    "PAD_TOKEN = 0\n",
    "SOS_TOKEN = 1\n",
    "EOS_TOKEN = 2\n",
    "\n",
    "\n",
    "class WordVocab():\n",
    "    def __init__(self):\n",
    "\n",
    "        # key가 token이고 value가 숫자\n",
    "        self.word2index = {\n",
    "            '<PAD>': PAD_TOKEN,\n",
    "            '<SOS>': SOS_TOKEN, \n",
    "            '<EOS>': EOS_TOKEN,\n",
    "        }\n",
    "\n",
    "        # 토큰 빈도수 저장\n",
    "        self.word2count = {}\n",
    "\n",
    "        # key가 숫자이고 value가 token\n",
    "        self.index2word = {\n",
    "            PAD_TOKEN: '<PAD>', \n",
    "            SOS_TOKEN: '<SOS>', \n",
    "            EOS_TOKEN: '<EOS>'\n",
    "        }\n",
    "        \n",
    "        self.n_words = 3  # PAD, SOS, EOS 포함한 token 개수\n",
    "\n",
    "    def add_sentence(self, sentence):\n",
    "        # 문장내 token들에 add_word() 적용\n",
    "        for word in sentence.split(' '):\n",
    "            self.add_word(word)\n",
    "\n",
    "    def add_word(self, word):\n",
    "        if word not in self.word2index:\n",
    "            # word가 word2index key에 없을 경우, \n",
    "\n",
    "            # n_words 번째 숫자 word2index의 key로 추가\n",
    "            self.word2index[word] = self.n_words\n",
    "\n",
    "            # word 빈도수 저장 함수에 key(word), value(빈도수) 추가\n",
    "            self.word2count[word] = 1\n",
    "\n",
    "            # word2index와 반대 내용 index2word에도 추가\n",
    "            self.index2word[self.n_words] = word\n",
    "\n",
    "            # word 개수 + 1\n",
    "            self.n_words += 1\n",
    "\n",
    "        # word가 word2index의 key로 있는 경우 word2count에서 해당 word의 value만 +1함    \n",
    "        else:\n",
    "            self.word2count[word] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "원문: SNS보면 나만 빼고 다 행복해보여\n",
      "==============================\n",
      "단어사전\n",
      "{'<PAD>': 0, '<SOS>': 1, '<EOS>': 2, 'SNS보면': 3, '나만': 4, '빼고': 5, '다': 6, '행복해보여': 7}\n"
     ]
    }
   ],
   "source": [
    "print(f'원문: {question[10]}')\n",
    "lang = WordVocab()\n",
    "lang.add_sentence(question[10])\n",
    "print('==='*10)\n",
    "print('단어사전')\n",
    "print(lang.word2index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Sentence: [50, 34, 25, 66, 48, 41]\n",
      "Output: [50, 34, 25, 66, 48, 41, 2, 0, 0, 0]\n",
      "Total Length: 10\n"
     ]
    }
   ],
   "source": [
    "# padding to sequence: 문장 길이 맞추기 코드 예시\n",
    "\n",
    "max_length = 10 # 패딩된 문장의 최대 길이\n",
    "sentence_length = 6 # 원본 문장의 길이\n",
    "\n",
    "# 3~99 사이 정수로 이루어진 size 형태의 랜덤 np 배열 생성 후 list로 변환\n",
    "sentence_tokens = np.random.randint(low=3, high=100, size=(sentence_length,))\n",
    "sentence_tokens = sentence_tokens.tolist()\n",
    "print(f'Generated Sentence: {sentence_tokens}')\n",
    "\n",
    "# max length보다 길이가 길 경우 9개 크기로 자르고 마지막에 EOS 토큰 추가\n",
    "sentence_tokens = sentence_tokens[:(max_length-1)]\n",
    "\n",
    "token_length = len(sentence_tokens)\n",
    "\n",
    "# 문장의 맨 끝부분에 <EOS> 토큰(2) 추가\n",
    "sentence_tokens.append(2)\n",
    "\n",
    "for i in range(token_length, max_length-1):\n",
    "    # 나머지 빈 곳에 <PAD> 토큰(0) 추가\n",
    "    sentence_tokens.append(0)\n",
    "\n",
    "print(f'Output: {sentence_tokens}')\n",
    "print(f'Total Length: {len(sentence_tokens)}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 전처리 프로세스 클래스화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from konlpy.tag import Mecab, Okt\n",
    "import os\n",
    "import pandas as pd\n",
    "import re \n",
    "\n",
    "class TextDataset(Dataset):\n",
    "    def __init__(self, csv_path, min_length=3, max_length=32):\n",
    "        super(TextDataset, self).__init__()\n",
    "        data_dir = 'data'\n",
    "\n",
    "        # 0,1,2 token 정의\n",
    "        self.PAD_TOKEN = 0\n",
    "        self.SOS_TOKEN = 1\n",
    "        self.EOS_TOKEN = 2\n",
    "\n",
    "        self.tagger = Okt()\n",
    "        self.max_length = max_length # 한 문장의 최대 길이\n",
    "\n",
    "        # 데이터 로드 \n",
    "        df = pd.read_csv(os.path.join(data_dir, csv_path))\n",
    "\n",
    "        # 한글 정규화\n",
    "        korean_pattern = r'[^ ?,.!A-Za-z0-9가-힣+]'\n",
    "        self.normalizer = re.compile(korean_pattern)\n",
    "\n",
    "        # src: 질의, tgt: 답변\n",
    "        src_clean = []\n",
    "        tgt_clean = []\n",
    "\n",
    "        # 단어사전 생성\n",
    "        wordvocab = WordVocab()\n",
    "\n",
    "        for _, row in df.iterrows():\n",
    "            src = row['Q']\n",
    "            tgt = row['A']\n",
    "\n",
    "            src = self.clean_text(src)\n",
    "            tgt = self.clean_text(tgt)\n",
    "\n",
    "            if len(src.split()) > min_length and len(tgt.split()) > min_length:\n",
    "                # 최소 길이 이상의 문장 단어만 추가\n",
    "                wordvocab.add_sentence(src)\n",
    "                wordvocab.add_sentence(tgt)\n",
    "                src_clean.append(src)\n",
    "                tgt_clean.append(tgt)\n",
    "        \n",
    "        self.srcs = src_clean\n",
    "        self.tgts = tgt_clean\n",
    "        self.wordvocb = wordvocab\n",
    "\n",
    "    def normalize(self, sentence):\n",
    "        return self.normalizer.sub(\"\", sentence)\n",
    "    \n",
    "    def clean_text(self, sentence):\n",
    "        sentence = self.normalize(sentence)\n",
    "        sentence = self.tagger.morphs(sentence)\n",
    "        sentence = ' '.join(sentence)\n",
    "        sentence = sentence.lower()\n",
    "        return sentence\n",
    "    \n",
    "    def texts_to_sequence(self, sentence):\n",
    "        # 문장 -> 시퀸스\n",
    "        return \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_tutorial",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
