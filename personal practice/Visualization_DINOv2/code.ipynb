{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "from einops import rearrange # 텐서 연산 돕는 도구로 코드 가독성 증진\n",
    "from torchvision.transforms import Normalize \n",
    "from torchvision.transforms.functional import resize \n",
    "from torchvision.utils import save_image \n",
    "from torchvision.io.image import read_image, ImageReadMode "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이미지를 읽고 resize\n",
    "I1 = read_image( \"img/1.jpg\" , ImageReadMode.RGB) \n",
    "I2 = read_image( \"img/2.jpg\" , ImageReadMode.RGB) \n",
    "\n",
    "H, W = 672 , 672\n",
    "I1 = resize(I1, (H, W)) \n",
    "I2 = resize(I2, (H, W))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 배치 차원을 쌓아서 배치 이미지 텐서 얻기(B*C*H*W)\n",
    "I = torch.stack([I1, I2], dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DINOv2 전처리 변환에 따른 정규화\n",
    "# [0, 1]로 정규화된 텐서의 평균 및 표준편차\n",
    "IMAGENET_DEFAULT_MEAN = ( 0.485 , 0.456 , 0.406 ) \n",
    "IMAGENET_DEFAULT_STD = ( 0.229 , 0.224 , 0.225 ) \n",
    "\n",
    "norm = Normalize(mean=IMAGENET_DEFAULT_MEAN, std=IMAGENET_DEFAULT_STD) \n",
    "\n",
    "I_norm = norm(I / 255 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://github.com/facebookresearch/dinov2/zipball/main\" to C:\\Users\\User/.cache\\torch\\hub\\main.zip\n",
      "C:\\Users\\User/.cache\\torch\\hub\\facebookresearch_dinov2_main\\dinov2\\layers\\swiglu_ffn.py:51: UserWarning: xFormers is not available (SwiGLU)\n",
      "  warnings.warn(\"xFormers is not available (SwiGLU)\")\n",
      "C:\\Users\\User/.cache\\torch\\hub\\facebookresearch_dinov2_main\\dinov2\\layers\\attention.py:33: UserWarning: xFormers is not available (Attention)\n",
      "  warnings.warn(\"xFormers is not available (Attention)\")\n",
      "C:\\Users\\User/.cache\\torch\\hub\\facebookresearch_dinov2_main\\dinov2\\layers\\block.py:40: UserWarning: xFormers is not available (Block)\n",
      "  warnings.warn(\"xFormers is not available (Block)\")\n",
      "Downloading: \"https://dl.fbaipublicfiles.com/dinov2/dinov2_vitb14/dinov2_vitb14_pretrain.pth\" to C:\\Users\\User/.cache\\torch\\hub\\checkpoints\\dinov2_vitb14_pretrain.pth\n",
      "100%|██████████| 330M/330M [00:35<00:00, 9.75MB/s] \n"
     ]
    }
   ],
   "source": [
    "# patch tokens 얻기\n",
    "dinov2 = torch.hub.load('facebookresearch/dinov2', 'dinov2_vitb14')\n",
    "features = dinov2.forward_features(I_norm)\n",
    "E_patch = features[\"x_norm_patchtokens\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PCA 이용해서 배경 제거\n",
    "E_patch_norm = rearrange(E_patch, \"B L E -> (B L) E\")\n",
    "\n",
    "# Getting Values of the pricipal value decomposition\n",
    "_, _, V = torch.pca_lowrank(E_patch_norm)\n",
    "\n",
    "# Projecting embeddings to the first component of the V matrix\n",
    "E_pca_1 = torch.matmul(E_patch_norm, V[:, :1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모든 값을 범위에 매핑하기 위해 min max scaling 사용\n",
    "def minmax_norm(x):\n",
    "    \"\"\"Min-max normalization\"\"\"\n",
    "    return (x - x.min(0).values) / (x.max(0).values - x.min(0).values)\n",
    "    \n",
    "E_pca_1_norm = minmax_norm(E_pca_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 임계값을 설정해 전경, 배경 패치 탐색\n",
    "M_fg = E_pca_1_norm.squeeze() > 0.5\n",
    "M_bg = E_pca_1_norm.squeeze() <= 0.5 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 전경 임베딩에서만 pca 계산\n",
    "# Getting Values of the pricipal value decomposition for foreground pixels\n",
    "_, _, V = torch.pca_lowrank(E_patch_norm[M_fg])\n",
    "\n",
    "# Projecting foreground embeddings to the first 3 component of the V matrix\n",
    "E_pca_3_fg = torch.matmul(E_patch_norm[M_fg], V[:, :3])\n",
    "E_pca_3_fg = minmax_norm(E_pca_3_fg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "B, L, _ = E_patch.shape\n",
    "Z = B * L\n",
    "I_draw = torch.zeros(Z,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 마스크 인덱싱을 통해 전경 픽셀 추가\n",
    "I_draw[M_fg] = E_pca_3_fg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이미지를 배치의 원래 모양으로 재조정\n",
    "I_draw = rearrange(I_draw, \"(B L) C -> B L C\", B=B)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "I_draw = rearrange(I_draw, \"B (h w) C -> B h w C\", h=H//14, w=W//14)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unpacking PCA images\n",
    "image_1_pca = I_draw[0]\n",
    "image_2_pca = I_draw[1]\n",
    "\n",
    "# To chanel first format torchvision format\n",
    "image_1_pca = rearrange(image_1_pca, \"H W C -> C H W\")\n",
    "image_2_pca = rearrange(image_2_pca, \"H W C -> C H W\")\n",
    "\n",
    "# Resizing it to ease visualization \n",
    "image_1_pca = resize(image_1_pca, (H,W))\n",
    "image_2_pca = resize(image_2_pca, (H,W))\n",
    "\n",
    "# Saving\n",
    "save_image(image_1_pca, \"img/image_1_pca.png\")\n",
    "save_image(image_2_pca, \"img/image_2_pca.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_tutorial",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
