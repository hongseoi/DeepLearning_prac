{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# pipeline\n",
    "Hugging Face 파이프라인은 다음과 같은 기능을 제공합니다.\n",
    "\n",
    "- 사전 훈련된 모델: 다양한 언어와 도메인에 대한 사전 훈련된 챗봇 모델을 제공합니다.\n",
    "- 모델 학습: 사용자 정의 챗봇 모델을 학습할 수 있는 도구를 제공합니다.\n",
    "- 모델 평가: 챗봇 모델의 성능을 평가할 수 있는 도구를 제공합니다.\n",
    "- 모델 배포: 챗봇 모델을 프로덕션 환경에 배포할 수 있는 도구를 제공합니다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\Desktop\\스터디\\Kaggle_Transcription_Study\\.conda\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.37.1\n"
     ]
    }
   ],
   "source": [
    "import transformers\n",
    "print(transformers.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 002. 감성분석\n",
    "- Distlbert 모델을 이용해 감성분석을 수행하고 아래 문장들이 긍정인지 부정인지 판단하라\n",
    "\n",
    "- \"I like Olympic games as it's very exciting\"\n",
    "- \"I'm against to hold Olympic games in Tokyo in terms of preventing the COVID19 to be spread\"\n",
    "\n",
    "### cf. 객체? 인스턴스?\n",
    "- 파이썬은 객체 지향 프로그래밍 언어로, 거의 모든 것은 객체로 이루어진다. 객체란 데이터와 함수의 모음이고, 클래스는 객체를 찍어내기 위한 거푸집이다. 클래스를 사용하면 조금의 변형만으로 다양한 객체를 양산할 수 있다.\n",
    "- 인스턴스는 클래스 객체를 사용해 만든 객체를 의미한다. 이렇게 클래스로 객체를 만드는 과정을 인스턴스화라고 한다.\n",
    "\n",
    "### distilbert?\n",
    "- maller, faster, cheaper, lighter: Introducing DistilBERT, a distilled version of BERT\n",
    "- has 40% less parameters than google-bert/bert-base-uncased, runs 60% faster while preserving over 95% of BERT’s performances as measured on the GLUE language understanding benchmark.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\User\\Desktop\\스터디\\Kaggle_Transcription_Study\\.conda\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilbert-base-uncased-finetuned-sst-2-english and revision af0f99b (https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "model.safetensors: 100%|██████████| 268M/268M [00:27<00:00, 9.80MB/s] \n",
      "c:\\Users\\User\\Desktop\\스터디\\Kaggle_Transcription_Study\\.conda\\Lib\\site-packages\\huggingface_hub\\file_download.py:149: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\User\\.cache\\huggingface\\hub\\models--distilbert-base-uncased-finetuned-sst-2-english. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n",
      "tokenizer_config.json: 100%|██████████| 48.0/48.0 [00:00<?, ?B/s]\n",
      "vocab.txt: 100%|██████████| 232k/232k [00:00<00:00, 9.44MB/s]\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "sentiment = pipeline('sentiment-analysis')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DistilBertForSequenceClassification(\n",
       "  (distilbert): DistilBertModel(\n",
       "    (embeddings): Embeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (transformer): Transformer(\n",
       "      (layer): ModuleList(\n",
       "        (0-5): 6 x TransformerBlock(\n",
       "          (attention): MultiHeadSelfAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (activation): GELUActivation()\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pre_classifier): Linear(in_features=768, out_features=768, bias=True)\n",
       "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
       "  (dropout): Dropout(p=0.2, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'label': 'POSITIVE', 'score': 0.9997889399528503}]\n",
      "[{'label': 'NEGATIVE', 'score': 0.9758421182632446}]\n"
     ]
    }
   ],
   "source": [
    "sentences = [\"I like Olympic games as it's very exciting\", \"I'm against to hold Olympic games in Tokyo in terms of preventing the COVID19 to be spread\"]\n",
    "print(sentiment(sentences[0]))\n",
    "print(sentiment(sentences[1]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 003\n",
    "- save question answering as qa and put question text to the keword argument 'question', and put 원본 텍스트 to keword argument 'context' \n",
    "\n",
    "cf. keyword argument\n",
    "특정한 파라미터명과 함께 함수에 전달되는 값"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilbert-base-cased-distilled-squad and revision 626af31 (https://huggingface.co/distilbert-base-cased-distilled-squad).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "config.json: 100%|██████████| 473/473 [00:00<?, ?B/s] \n",
      "c:\\Users\\User\\Desktop\\스터디\\Kaggle_Transcription_Study\\.conda\\Lib\\site-packages\\huggingface_hub\\file_download.py:149: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\User\\.cache\\huggingface\\hub\\models--distilbert-base-cased-distilled-squad. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n",
      "model.safetensors: 100%|██████████| 261M/261M [00:27<00:00, 9.60MB/s] \n",
      "tokenizer_config.json: 100%|██████████| 29.0/29.0 [00:00<00:00, 29.0kB/s]\n",
      "vocab.txt: 100%|██████████| 213k/213k [00:00<00:00, 2.37MB/s]\n",
      "tokenizer.json: 100%|██████████| 436k/436k [00:00<00:00, 664kB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'score': 0.0077745309099555016, 'start': 416, 'end': 467, 'answer': 'largest relative to body size of any extant species'}\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "qa = pipeline('question-answering')\n",
    "\n",
    "# 질문\n",
    "question = \"How do you think about human?\"\n",
    "\n",
    "# 분석대상\n",
    "context = \"\"\"\n",
    "\n",
    "Humans (Homo sapiens) are bipedal primates characterized by their high intelligence, complex social structures, and ability to use language. Here's a breakdown of some key aspects of what makes us human:\n",
    "\n",
    "Biology:\n",
    "\n",
    "Species: Homo sapiens, the most recent member of the genus Homo.\n",
    "Anatomy: Upright walking posture, large and complex brains, opposable thumbs, and advanced vocal cords.\n",
    "Brain: The human brain is the largest relative to body size of any extant species. It allows for complex cognitive abilities like reasoning, problem-solving, abstract thinking, and creativity.\n",
    "Senses: Humans have well-developed senses of sight, hearing, touch, smell, and taste, enabling them to interact with their environment effectively.\n",
    "Behavior:\n",
    "\n",
    "Social: Humans are highly social creatures who form complex relationships with each other. We cooperate in groups to achieve common goals, share knowledge and resources, and provide emotional support.\n",
    "Language: Humans have a unique ability to use complex language for communication. Language allows us to share ideas, thoughts, and feelings with others, and it plays a vital role in our social interactions and cultural development.\n",
    "Culture: Humans create and transmit culture across generations. Culture includes our customs, traditions, beliefs, art, music, and technology. It shapes our behavior and identity.\n",
    "Tool Use: Humans have a long history of using and developing tools. Tools allow us to modify our environment, gather food, and build complex structures.\n",
    "Evolution:\n",
    "\n",
    "Humans evolved from ape-like ancestors over millions of years. The exact timeline and details are still being studied, but key factors in our evolution include:\n",
    "Bipedalism (walking upright)\n",
    "Increased brain size\n",
    "Development of language\n",
    "Use of tools\n",
    "Uniqueness:\n",
    "\n",
    "While humans share some characteristics with other animals, several aspects set us apart:\n",
    "\n",
    "High Intelligence: Our large brains allow for complex cognitive abilities that enable us to solve problems, adapt to new situations, and make plans for the future.\n",
    "Language: Our ability to use complex language allows for sophisticated communication and the transmission of knowledge across generations.\n",
    "Culture: Humans create and transmit culture, which shapes our behavior and identity.\n",
    "Self-Awareness: Humans are aware of ourselves as individuals and have a sense of agency over our actions.\n",
    "The study of humans is a vast field that encompasses many disciplines, including biology, anthropology, psychology, sociology, and history. Scientists continue to learn more about what makes us human and how we came to be the way we are.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "print(qa(question=question, context=context))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DistilBertForQuestionAnswering(\n",
       "  (distilbert): DistilBertModel(\n",
       "    (embeddings): Embeddings(\n",
       "      (word_embeddings): Embedding(28996, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (transformer): Transformer(\n",
       "      (layer): ModuleList(\n",
       "        (0-5): 6 x TransformerBlock(\n",
       "          (attention): MultiHeadSelfAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (activation): GELUActivation()\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (qa_outputs): Linear(in_features=768, out_features=2, bias=True)\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# qa의 default 모델 확인\n",
    "qa.model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DistillBERT 파인튜닝 및 평가\n",
    "004 ~ 013\n",
    "\n",
    "- 트랜스포머 기반의 사전학습 모델의 훌륭한 점은 사전학습모델이 토큰과 문장들의 관계를 unlabeled 대규모 텍스트 데이터를 갖고 학습을 완료했다는 점\n",
    "- 이후 labeled 소규모 데이터를 대상으로 finetuning을 하면 높은 정확도를 얻을 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# CUDA 사용 가능 여부 확인\n",
    "device = torch.device(\"cuda\")\n",
    "print(torch.cuda.is_available())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
