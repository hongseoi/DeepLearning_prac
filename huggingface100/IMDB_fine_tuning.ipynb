{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 003. IMDB\n",
    "- 영화 리뷰 긍/부정 판단 위한 sentiment analysis dataset\n",
    "- 25000 train data, 25000 test data로 구성\n",
    "- torxhtext를 이용해 데이터 다운로드하기\n",
    "\n",
    "``` Python\n",
    "! pip install torchtext=0.15.2 # 자연어 처리 작업\n",
    "! pip install portalocker=2.7.0 # 여러 프로세스가 동일한  파일을 동시에 접근할 때 충돌 방지\n",
    "! pip install accelerate -U # pytorch 모델의 학습 및 평가 가속화\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torchtext==0.15.2 in c:\\users\\user\\desktop\\스터디\\kaggle_transcription_study\\.conda\\lib\\site-packages (0.15.2)\n",
      "Requirement already satisfied: tqdm in c:\\users\\user\\desktop\\스터디\\kaggle_transcription_study\\.conda\\lib\\site-packages (from torchtext==0.15.2) (4.66.1)\n",
      "Requirement already satisfied: requests in c:\\users\\user\\desktop\\스터디\\kaggle_transcription_study\\.conda\\lib\\site-packages (from torchtext==0.15.2) (2.31.0)\n",
      "Requirement already satisfied: torch==2.0.1 in c:\\users\\user\\desktop\\스터디\\kaggle_transcription_study\\.conda\\lib\\site-packages (from torchtext==0.15.2) (2.0.1)\n",
      "Requirement already satisfied: numpy in c:\\users\\user\\desktop\\스터디\\kaggle_transcription_study\\.conda\\lib\\site-packages (from torchtext==0.15.2) (1.26.3)\n",
      "Requirement already satisfied: torchdata==0.6.1 in c:\\users\\user\\desktop\\스터디\\kaggle_transcription_study\\.conda\\lib\\site-packages (from torchtext==0.15.2) (0.6.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\user\\desktop\\스터디\\kaggle_transcription_study\\.conda\\lib\\site-packages (from torch==2.0.1->torchtext==0.15.2) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\user\\desktop\\스터디\\kaggle_transcription_study\\.conda\\lib\\site-packages (from torch==2.0.1->torchtext==0.15.2) (4.9.0)\n",
      "Requirement already satisfied: sympy in c:\\users\\user\\desktop\\스터디\\kaggle_transcription_study\\.conda\\lib\\site-packages (from torch==2.0.1->torchtext==0.15.2) (1.12)\n",
      "Requirement already satisfied: networkx in c:\\users\\user\\desktop\\스터디\\kaggle_transcription_study\\.conda\\lib\\site-packages (from torch==2.0.1->torchtext==0.15.2) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\user\\desktop\\스터디\\kaggle_transcription_study\\.conda\\lib\\site-packages (from torch==2.0.1->torchtext==0.15.2) (3.1.3)\n",
      "Requirement already satisfied: urllib3>=1.25 in c:\\users\\user\\desktop\\스터디\\kaggle_transcription_study\\.conda\\lib\\site-packages (from torchdata==0.6.1->torchtext==0.15.2) (2.1.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\user\\desktop\\스터디\\kaggle_transcription_study\\.conda\\lib\\site-packages (from requests->torchtext==0.15.2) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\user\\desktop\\스터디\\kaggle_transcription_study\\.conda\\lib\\site-packages (from requests->torchtext==0.15.2) (3.6)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\user\\desktop\\스터디\\kaggle_transcription_study\\.conda\\lib\\site-packages (from requests->torchtext==0.15.2) (2023.11.17)\n",
      "Requirement already satisfied: colorama in c:\\users\\user\\desktop\\스터디\\kaggle_transcription_study\\.conda\\lib\\site-packages (from tqdm->torchtext==0.15.2) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\user\\desktop\\스터디\\kaggle_transcription_study\\.conda\\lib\\site-packages (from jinja2->torch==2.0.1->torchtext==0.15.2) (2.1.4)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\user\\desktop\\스터디\\kaggle_transcription_study\\.conda\\lib\\site-packages (from sympy->torch==2.0.1->torchtext==0.15.2) (1.3.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install torchtext==0.15.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting portalocker==2.7.0\n",
      "  Using cached portalocker-2.7.0-py2.py3-none-any.whl.metadata (6.8 kB)\n",
      "Requirement already satisfied: pywin32>=226 in c:\\users\\user\\desktop\\스터디\\kaggle_transcription_study\\.conda\\lib\\site-packages (from portalocker==2.7.0) (305.1)\n",
      "Using cached portalocker-2.7.0-py2.py3-none-any.whl (15 kB)\n",
      "Installing collected packages: portalocker\n",
      "Successfully installed portalocker-2.7.0\n"
     ]
    }
   ],
   "source": [
    "!pip install portalocker==2.7.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting accelerate\n",
      "  Using cached accelerate-0.27.2-py3-none-any.whl.metadata (18 kB)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\user\\desktop\\스터디\\kaggle_transcription_study\\.conda\\lib\\site-packages (from accelerate) (1.26.3)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\user\\desktop\\스터디\\kaggle_transcription_study\\.conda\\lib\\site-packages (from accelerate) (23.2)\n",
      "Requirement already satisfied: psutil in c:\\users\\user\\desktop\\스터디\\kaggle_transcription_study\\.conda\\lib\\site-packages (from accelerate) (5.9.0)\n",
      "Requirement already satisfied: pyyaml in c:\\users\\user\\desktop\\스터디\\kaggle_transcription_study\\.conda\\lib\\site-packages (from accelerate) (6.0.1)\n",
      "Requirement already satisfied: torch>=1.10.0 in c:\\users\\user\\desktop\\스터디\\kaggle_transcription_study\\.conda\\lib\\site-packages (from accelerate) (2.0.1)\n",
      "Requirement already satisfied: huggingface-hub in c:\\users\\user\\desktop\\스터디\\kaggle_transcription_study\\.conda\\lib\\site-packages (from accelerate) (0.20.3)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in c:\\users\\user\\desktop\\스터디\\kaggle_transcription_study\\.conda\\lib\\site-packages (from accelerate) (0.4.2)\n",
      "Requirement already satisfied: filelock in c:\\users\\user\\desktop\\스터디\\kaggle_transcription_study\\.conda\\lib\\site-packages (from torch>=1.10.0->accelerate) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\user\\desktop\\스터디\\kaggle_transcription_study\\.conda\\lib\\site-packages (from torch>=1.10.0->accelerate) (4.9.0)\n",
      "Requirement already satisfied: sympy in c:\\users\\user\\desktop\\스터디\\kaggle_transcription_study\\.conda\\lib\\site-packages (from torch>=1.10.0->accelerate) (1.12)\n",
      "Requirement already satisfied: networkx in c:\\users\\user\\desktop\\스터디\\kaggle_transcription_study\\.conda\\lib\\site-packages (from torch>=1.10.0->accelerate) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\user\\desktop\\스터디\\kaggle_transcription_study\\.conda\\lib\\site-packages (from torch>=1.10.0->accelerate) (3.1.3)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\user\\desktop\\스터디\\kaggle_transcription_study\\.conda\\lib\\site-packages (from huggingface-hub->accelerate) (2023.12.2)\n",
      "Requirement already satisfied: requests in c:\\users\\user\\desktop\\스터디\\kaggle_transcription_study\\.conda\\lib\\site-packages (from huggingface-hub->accelerate) (2.31.0)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in c:\\users\\user\\desktop\\스터디\\kaggle_transcription_study\\.conda\\lib\\site-packages (from huggingface-hub->accelerate) (4.66.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\user\\desktop\\스터디\\kaggle_transcription_study\\.conda\\lib\\site-packages (from tqdm>=4.42.1->huggingface-hub->accelerate) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\user\\desktop\\스터디\\kaggle_transcription_study\\.conda\\lib\\site-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.4)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\user\\desktop\\스터디\\kaggle_transcription_study\\.conda\\lib\\site-packages (from requests->huggingface-hub->accelerate) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\user\\desktop\\스터디\\kaggle_transcription_study\\.conda\\lib\\site-packages (from requests->huggingface-hub->accelerate) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\user\\desktop\\스터디\\kaggle_transcription_study\\.conda\\lib\\site-packages (from requests->huggingface-hub->accelerate) (2.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\user\\desktop\\스터디\\kaggle_transcription_study\\.conda\\lib\\site-packages (from requests->huggingface-hub->accelerate) (2023.11.17)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\user\\desktop\\스터디\\kaggle_transcription_study\\.conda\\lib\\site-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\n",
      "Using cached accelerate-0.27.2-py3-none-any.whl (279 kB)\n",
      "Installing collected packages: accelerate\n",
      "Successfully installed accelerate-0.27.2\n"
     ]
    }
   ],
   "source": [
    "!pip install accelerate -U"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 위까지 실행 후 restart\n",
    "from torchtext.datasets import IMDB\n",
    "\n",
    "train_iter = IMDB(split='train')\n",
    "test_iter = IMDB(split='test')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, \"I LOVED this movie! I am biased seeing as I am a huge Disney fan, but I really enjoyed myself. The action takes off running in the beginning of the film and just keeps going! This is a bit of a departure for Disney, they don't spend quite as much time on character development (my husband pointed this out)and there are no musical numbers. It is strictly action adventure. I thoroughly enjoyed it and recommend it to anyone who loves Disney, be they young or old.\")\n",
      "(1, 'This was an abysmal show. In short it was about this kid called Doug who guilt-tripped a lot. Seriously he could feel guilty over killing a fly then feeling guilty over feeling guilty for killing the fly and so forth. The animation was grating and unpleasant and the jokes cheap. <br /><br />It aired here in Sweden as a part of the \"Disney time\" show and i remember liking it some what but then i turned 13.<br /><br />I never got why some of the characters were green and purple too. What was up with that? <br /><br />Truly a horrible show. Appareantly it spawned a movie which i\\'ve never seen but i don\\'t have any great expectations for that one either.')\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "random.seed(6)\n",
    "\n",
    "# xxx_iter를 리스트로 변경\n",
    "train_list = list(train_iter)\n",
    "test_list = list(test_iter)\n",
    "\n",
    "# 리스트 중 1000개씩 랜덤샘플링\n",
    "train_list_small = random.sample(train_list, 1000)\n",
    "test_list_small = random.sample(test_list, 1000)\n",
    "\n",
    "# 각 변수의 첫번째 원소 출력\n",
    "print(train_list_small[0])\n",
    "print(test_list_small[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 005. label encoding\n",
    "위의 데이터셋은 (텍스트, 레이블) 형태로 구성되어 있으며, 레이블의 경우 2는 긍정, 1은 부정으로 구성되어 있다. 긍정을 1, 부정을 0으로 바꾸고 이걸 각각 train_texts, train_labels, test_texts, test_labels에 저장하라"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_texts  = []\n",
    "train_labels = []\n",
    "test_texts = []\n",
    "test_labels = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "for label, text in train_list_small:\n",
    "    train_labels.append(1 if label==2 else 0)\n",
    "    train_texts.append(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "for label, text in test_list_small:\n",
    "    test_labels.append(1 if label==2 else 0)\n",
    "    test_texts.append(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "I LOVED this movie! I am biased seeing as I am a huge Disney fan, but I really enjoyed myself. The action takes off running in the beginning of the film and just keeps going! This is a bit of a departure for Disney, they don't spend quite as much time on character development (my husband pointed this out)and there are no musical numbers. It is strictly action adventure. I thoroughly enjoyed it and recommend it to anyone who loves Disney, be they young or old.\n"
     ]
    }
   ],
   "source": [
    "print(train_labels[0])\n",
    "print(train_texts[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 006. 학습 및 검증 데이터 분리\n",
    "1000개를 8:2로 나누어라"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800\n",
      "800\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_texts, val_texts, train_labels, val_labels = train_test_split(train_texts, train_labels, test_size=0.2, random_state=3)\n",
    "\n",
    "print(len(train_labels))\n",
    "print(len(train_texts))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 007. 토크나이징 및 인코딩\n",
    "위에서 추출한 train, val, test 데이터를 pretrained distilbert-base-uncased 모델에 투입하기 위해 토크나이저를 사용해서 인코딩하라"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\Desktop\\스터디\\Kaggle_Transcription_Study\\.conda\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import DistilBertTokenizerFast\n",
    "\n",
    "tokenizer = DistilBertTokenizerFast.from_pretrained('distilbert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[101, 4937, 11350, 2038, 2048]\n"
     ]
    }
   ],
   "source": [
    "# 토크나이저 실행\n",
    "train_encodings = tokenizer(train_texts, truncation=True, padding=True) # truncation: 모델의 default max_length를 넘는 입력 부분을 더 이상 받지 않고 절단함\n",
    "val_encodings = tokenizer(val_texts, truncation=True, padding=True)\n",
    "test_encodings = tokenizer(test_texts, truncation=True, padding=True)\n",
    "\n",
    "print(train_encodings['input_ids'][0][:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['input_ids', 'attention_mask'])\n"
     ]
    }
   ],
   "source": [
    "print(train_encodings.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[101, 4937, 11350, 2038, 2048]\n",
      "WARNING:tensorflow:From c:\\Users\\User\\Desktop\\스터디\\Kaggle_Transcription_Study\\.conda\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "[CLS] cat soup has two\n"
     ]
    }
   ],
   "source": [
    "print(train_encodings['input_ids'][0][:5])\n",
    "print(tokenizer.decode(train_encodings['input_ids'][0][:5]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 008. 데이터세트 클래스 생성\n",
    "- torch.utils.data.Dataset을 상속하는 IMDBDataset이라는 클래스 작성하기\n",
    "- 문제 007의 imdb 데이터셋에서 학습한 train/val/test encodings를 입력해서 클래스 인스턴스화하기\n",
    "\n",
    "cf. __init__은 인스턴스화에 생기는 generator이다. generator는 클래스로 객체를 생성할 때 자동으로 호출되는 메서드로, 객체를 미리 설정한 값으로 초기화한다. 그리고 클래스를 구성하는 arguments, variable, function을 정의한다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "class IMDBDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        # {'key':'value'} 형태의 딕셔너리 구조\n",
    "        # val[idx], label[idx]의 데이터를 파이토치 텐서로 변환\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        item['labels'] = torch.tensor(self.labels[idx])\n",
    "        return item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.IMDBDataset at 0x24079d15a50>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset = IMDBDataset(train_encodings, train_labels)\n",
    "val_dataset = IMDBDataset(val_encodings, val_labels)\n",
    "test_dataset = IMDBDataset(test_encodings, test_labels)\n",
    "\n",
    "test_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['input_ids', 'attention_mask', 'labels'])\n"
     ]
    }
   ],
   "source": [
    "# 각 데이터셋 확인: iterable 객체이므로 for문 사용가능\n",
    "for i in train_dataset:\n",
    "    print(i.keys())\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- input_ids: 단어 ID\n",
    "- attention_mask: 패딩 위치(실제 입력 토큰과 패딩 토큰 구분)\n",
    "- labels\n",
    "\n",
    "## 사전학습 모델 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "model.safetensors: 100%|██████████| 268M/268M [00:27<00:00, 9.72MB/s] \n",
      "c:\\Users\\User\\Desktop\\스터디\\Kaggle_Transcription_Study\\.conda\\Lib\\site-packages\\huggingface_hub\\file_download.py:149: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\User\\.cache\\huggingface\\hub\\models--distilbert-base-uncased. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DistilBertForSequenceClassification(\n",
       "  (distilbert): DistilBertModel(\n",
       "    (embeddings): Embeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (transformer): Transformer(\n",
       "      (layer): ModuleList(\n",
       "        (0-5): 6 x TransformerBlock(\n",
       "          (attention): MultiHeadSelfAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (activation): GELUActivation()\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pre_classifier): Linear(in_features=768, out_features=768, bias=True)\n",
       "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
       "  (dropout): Dropout(p=0.2, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import DistilBertForSequenceClassification\n",
    "\n",
    "# 1. pretrained model 불러오기\n",
    "model = DistilBertForSequenceClassification.from_pretrained(\"distilbert-base-uncased\")\n",
    "\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. training_argument 설정\n",
    "from transformers import TrainingArguments\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./result',\n",
    "    num_train_epochs = 8,\n",
    "    per_device_train_batch_size = 16, # 학습시 디바이스별 미니 배치 수\n",
    "    per_device_eval_batch_size = 64, # 평가시 ~\n",
    "    warmup_steps = 500, # 학습률 스케줄링용 웜업 스텝수\n",
    "    weight_decay=0.01, # 가중치 감소 강도\n",
    "    logging_dir = './logs',\n",
    "    logging_steps=10,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 3. 모델을 GPU에 전송\n",
    "import torch\n",
    "\n",
    "torch.cuda.is_available()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu Mar 21 15:17:31 2024       \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 537.42                 Driver Version: 537.42       CUDA Version: 12.2     |\n",
      "|-----------------------------------------+----------------------+----------------------+\n",
      "| GPU  Name                     TCC/WDDM  | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                      |               MIG M. |\n",
      "|=========================================+======================+======================|\n",
      "|   0  NVIDIA GeForce RTX 3060 Ti   WDDM  | 00000000:07:00.0  On |                  N/A |\n",
      "|  0%   36C    P8              20W / 220W |   1813MiB /  8192MiB |      0%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "                                                                                         \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                            |\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
      "|        ID   ID                                                             Usage      |\n",
      "|=======================================================================================|\n",
      "|    0   N/A  N/A      1124    C+G   ...siveControlPanel\\SystemSettings.exe    N/A      |\n",
      "|    0   N/A  N/A      5080    C+G   C:\\Windows\\explorer.exe                   N/A      |\n",
      "|    0   N/A  N/A      5400    C+G   ...crosoft\\Edge\\Application\\msedge.exe    N/A      |\n",
      "|    0   N/A  N/A      7408    C+G   ...nt.CBS_cw5n1h2txyewy\\SearchHost.exe    N/A      |\n",
      "|    0   N/A  N/A      7528    C+G   ...__8wekyb3d8bbwe\\Microsoft.Notes.exe    N/A      |\n",
      "|    0   N/A  N/A      7552    C+G   ....0_x64__8wekyb3d8bbwe\\HxOutlook.exe    N/A      |\n",
      "|    0   N/A  N/A      7568    C+G   ...__8wekyb3d8bbwe\\WindowsTerminal.exe    N/A      |\n",
      "|    0   N/A  N/A      7592    C+G   ...2txyewy\\StartMenuExperienceHost.exe    N/A      |\n",
      "|    0   N/A  N/A     12664    C+G   ...GeForce Experience\\NVIDIA Share.exe    N/A      |\n",
      "|    0   N/A  N/A     13796    C+G   ...CBS_cw5n1h2txyewy\\TextInputHost.exe    N/A      |\n",
      "|    0   N/A  N/A     13836    C+G   ...GeForce Experience\\NVIDIA Share.exe    N/A      |\n",
      "|    0   N/A  N/A     15112    C+G   ...Programs\\Microsoft VS Code\\Code.exe    N/A      |\n",
      "|    0   N/A  N/A     17064    C+G   ...oogle\\Chrome\\Application\\chrome.exe    N/A      |\n",
      "|    0   N/A  N/A     17476    C+G   ...on\\122.0.2365.92\\msedgewebview2.exe    N/A      |\n",
      "|    0   N/A  N/A     17508    C+G   ...US\\ArmouryDevice\\asus_framework.exe    N/A      |\n",
      "|    0   N/A  N/A     17640    C+G   ...e Stream\\88.0.0.0\\GoogleDriveFS.exe    N/A      |\n",
      "|    0   N/A  N/A     19760    C+G   ...les\\Microsoft OneDrive\\OneDrive.exe    N/A      |\n",
      "|    0   N/A  N/A     20580    C+G   ...ekyb3d8bbwe\\PhoneExperienceHost.exe    N/A      |\n",
      "|    0   N/A  N/A     20808    C+G   ...al\\Discord\\app-1.0.9036\\Discord.exe    N/A      |\n",
      "|    0   N/A  N/A     22392    C+G   ...ta\\Local\\Programs\\Notion\\Notion.exe    N/A      |\n",
      "|    0   N/A  N/A     23152    C+G   ...5n1h2txyewy\\ShellExperienceHost.exe    N/A      |\n",
      "|    0   N/A  N/A     23160    C+G   ...546_x64__8wekyb3d8bbwe\\ms-teams.exe    N/A      |\n",
      "|    0   N/A  N/A     23484    C+G   ...\\Local\\slack\\app-4.36.140\\slack.exe    N/A      |\n",
      "|    0   N/A  N/A     24952    C+G   ...on\\122.0.2365.80\\msedgewebview2.exe    N/A      |\n",
      "|    0   N/A  N/A     25964    C+G   ...on\\122.0.2365.92\\msedgewebview2.exe    N/A      |\n",
      "|    0   N/A  N/A     26484    C+G   ...on\\122.0.2365.80\\msedgewebview2.exe    N/A      |\n",
      "|    0   N/A  N/A     32012    C+G   ...esktop\\app-3.3.11\\GitHubDesktop.exe    N/A      |\n",
      "|    0   N/A  N/A     33920    C+G   ...soft Office\\root\\Office16\\EXCEL.EXE    N/A      |\n",
      "|    0   N/A  N/A     35692    C+G   ...__8wekyb3d8bbwe\\Notepad\\Notepad.exe    N/A      |\n",
      "+---------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "undefined.undefined.undefined"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
